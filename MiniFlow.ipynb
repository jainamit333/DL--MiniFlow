{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check when no hidden layer is passed\n",
    "#currently only work for single output\n",
    "class MiniFlow():\n",
    "     #input - actual input, output - actual output , hidden layer - array of size of hidden layers\n",
    "     # preprocess_function - it will return train_data,train_output\n",
    "     # learning_rate = how fast learning rate should be.\n",
    "        \n",
    "    def __init__(self,inputs,outputs,hidden_layers,preprocess_function,learning_rate = 0.1):\n",
    "        \n",
    "        np.random.seed(0)\n",
    "        self.inputs,self.outputs = preprocess_function(inputs,outputs)\n",
    "        self.initialization(inputs,outputs,hidden_layers,learning_rate)\n",
    "        \n",
    "    def initialization(self,inputs,outputs,hidden_layers,learning_rate):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.number_of_hidden_layers = len(hidden_layers)\n",
    "        self.weights =  dict()\n",
    "        self.output_size = outputs.shape[1]\n",
    "        row = inputs.shape[1]\n",
    "        col = hidden_layers[0]\n",
    "        \n",
    "        counter = 0\n",
    "        for i in range(self.number_of_hidden_layers+1):\n",
    "            print('row',row,'col',col)\n",
    "            self.weights.update({i:np.random.rand(row,col)})\n",
    "            row = col\n",
    "            if i + 1 >= self.number_of_hidden_layers:\n",
    "                col = self.output_size\n",
    "            else:\n",
    "                col = hidden_layers[counter+1]\n",
    "            counter = counter+1\n",
    "            \n",
    "    def get_weights(self):\n",
    "        return self.weights                \n",
    "            \n",
    "    def train(self,number_of_epoch,batch_size):\n",
    "        \n",
    "        #currently we not using epoch and batch size\n",
    "        print(self.weights)\n",
    "        for j in tqdm(range(number_of_epoch)):\n",
    "            batch = np.random.choice(len(self.inputs), size=batch_size)\n",
    "            X,Y = self.inputs[batch],self.outputs[batch]       \n",
    "            for i in range(len(X)):\n",
    "                self.feed_forward_backward(X[i],Y[i],i)\n",
    "        print(self.weights)                    \n",
    "        pass\n",
    "    def feed_forward(self,inputs):\n",
    "        \n",
    "        result = inputs\n",
    "        self.temp_inputs = dict()\n",
    "        for i in range(self.number_of_hidden_layers+1):\n",
    "            self.temp_inputs.update({i:np.asmatrix(result)})\n",
    "            result = np.dot(result,self.weights[i])\n",
    "        result = self.sigmoid(result)\n",
    "        return result\n",
    "\n",
    "    def feed_forward_backward(self,inputs,outputs,counter_value):\n",
    "        \n",
    "        prediction = self.feed_forward(inputs)\n",
    "\n",
    "        #last layer error and delta\n",
    "        error = self.error_calculation(outputs,prediction)\n",
    "        error_delta = error * self.sigmoid_derivative(prediction)        \n",
    "        error_delta = error_delta.reshape(1,1)\n",
    "\n",
    "        #actual back propogation\n",
    "        for i in reversed(range(self.number_of_hidden_layers+1)):\n",
    "\n",
    "            current_weight = self.weights[i]\n",
    "            temp = (self.temp_inputs[i].T.dot(error_delta)*self.learning_rate)\n",
    "            \n",
    "            self.weights[i] = self.weights[i] + temp\n",
    "            error = np.asmatrix(error_delta.dot(current_weight.T))\n",
    "            error_delta = error\n",
    "        \n",
    "        \n",
    "    def error_calculation(self,actual,predicted):\n",
    "        return actual - predicted\n",
    "        \n",
    "    def sigmoid(self,data):\n",
    "        return 1/(1+np.exp(-data))\n",
    "    \n",
    "    def sigmoid_derivative(self,data):\n",
    "        return data * (1- data)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input = np.array([[2.9,2.4,3.0,4.2],[5.0,6.0,7.0,8.0]],dtype=float)\n",
    "test_label = np.array([[0],[1]])\n",
    "test_hidden_layers = [2]\n",
    "\n",
    "def preprocess_function(inputs,outputs):\n",
    "    return inputs,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 4 col 2\n",
      "row 2 col 1\n"
     ]
    }
   ],
   "source": [
    "netowrk = MiniFlow(inputs=test_input,outputs=test_label,hidden_layers=test_hidden_layers,\n",
    "                   preprocess_function=preprocess_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[ 0.5488135 ,  0.71518937],\n",
       "        [ 0.60276338,  0.54488318],\n",
       "        [ 0.4236548 ,  0.64589411],\n",
       "        [ 0.43758721,  0.891773  ]]), 1: array([[ 0.96366276],\n",
       "        [ 0.38344152]])}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netowrk.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.27463021316008e-05"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.99991724 * netowrk.sigmoid_derivative(0.99991724)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netowrk.train(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: matrix([[ 0.54883663,  0.71519857],\n",
       "         [ 0.60278251,  0.5448908 ],\n",
       "         [ 0.42367872,  0.64590363],\n",
       "         [ 0.4376207 ,  0.89178633]]), 1: matrix([[ 0.96371362],\n",
       "         [ 0.38351653]])}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netowrk.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test MiniFLow Network on data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('HR_comma_sep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salary_mapping = {'low':1,'medium':3,'high':5}\n",
    "raw_data['salary'] = raw_data.salary.replace(salary_mapping)\n",
    "dummies = pd.get_dummies(raw_data['sales'], prefix='sales', drop_first=False)\n",
    "raw_data = pd.concat([raw_data, dummies], axis=1)\n",
    "raw_data = raw_data.drop('sales',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_be_normalized = ['number_project','average_montly_hours','time_spend_company','salary']\n",
    "scaled_features = {}\n",
    "for each in columns_to_be_normalized:\n",
    "    mean, std = raw_data[each].mean(), raw_data[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    raw_data.loc[:, each] = (raw_data[each] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_columns = raw_data.columns.size\n",
    "number_of_rows = len(raw_data)\n",
    "test_size = 1000\n",
    "validation_size = 3000\n",
    "target_field = ['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = shuffle(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = raw_data[:test_size]\n",
    "validation_data = raw_data[test_size:test_size+validation_size]\n",
    "train_data = raw_data[test_size+validation_size:len(raw_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features,train_target = train_data.drop(target_field,axis=1),train_data[target_field]\n",
    "validation_features,validation_target = validation_data.drop(target_field,axis=1),validation_data[target_field]\n",
    "test_features,test_target = test_data.drop(target_field,axis=1),test_data[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_hr_data(inputs,outputs):\n",
    "    return inputs,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y, Y):\n",
    "    return np.mean((y-Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10999, 18)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 18)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 18 col 9\n",
      "row 9 col 5\n",
      "row 5 col 1\n"
     ]
    }
   ],
   "source": [
    "neuralNetwork =  MiniFlow(inputs=train_features.values,outputs=train_target.values,hidden_layers=[9,5],learning_rate=0.1,preprocess_function=process_hr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/25000 [00:00<06:19, 65.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([[ 0.5488135 ,  0.71518937,  0.60276338,  0.54488318,  0.4236548 ,\n",
      "         0.64589411,  0.43758721,  0.891773  ,  0.96366276],\n",
      "       [ 0.38344152,  0.79172504,  0.52889492,  0.56804456,  0.92559664,\n",
      "         0.07103606,  0.0871293 ,  0.0202184 ,  0.83261985],\n",
      "       [ 0.77815675,  0.87001215,  0.97861834,  0.79915856,  0.46147936,\n",
      "         0.78052918,  0.11827443,  0.63992102,  0.14335329],\n",
      "       [ 0.94466892,  0.52184832,  0.41466194,  0.26455561,  0.77423369,\n",
      "         0.45615033,  0.56843395,  0.0187898 ,  0.6176355 ],\n",
      "       [ 0.61209572,  0.616934  ,  0.94374808,  0.6818203 ,  0.3595079 ,\n",
      "         0.43703195,  0.6976312 ,  0.06022547,  0.66676672],\n",
      "       [ 0.67063787,  0.21038256,  0.1289263 ,  0.31542835,  0.36371077,\n",
      "         0.57019677,  0.43860151,  0.98837384,  0.10204481],\n",
      "       [ 0.20887676,  0.16130952,  0.65310833,  0.2532916 ,  0.46631077,\n",
      "         0.24442559,  0.15896958,  0.11037514,  0.65632959],\n",
      "       [ 0.13818295,  0.19658236,  0.36872517,  0.82099323,  0.09710128,\n",
      "         0.83794491,  0.09609841,  0.97645947,  0.4686512 ],\n",
      "       [ 0.97676109,  0.60484552,  0.73926358,  0.03918779,  0.28280696,\n",
      "         0.12019656,  0.2961402 ,  0.11872772,  0.31798318],\n",
      "       [ 0.41426299,  0.0641475 ,  0.69247212,  0.56660145,  0.26538949,\n",
      "         0.52324805,  0.09394051,  0.5759465 ,  0.9292962 ],\n",
      "       [ 0.31856895,  0.66741038,  0.13179786,  0.7163272 ,  0.28940609,\n",
      "         0.18319136,  0.58651293,  0.02010755,  0.82894003],\n",
      "       [ 0.00469548,  0.67781654,  0.27000797,  0.73519402,  0.96218855,\n",
      "         0.24875314,  0.57615733,  0.59204193,  0.57225191],\n",
      "       [ 0.22308163,  0.95274901,  0.44712538,  0.84640867,  0.69947928,\n",
      "         0.29743695,  0.81379782,  0.39650574,  0.8811032 ],\n",
      "       [ 0.58127287,  0.88173536,  0.69253159,  0.72525428,  0.50132438,\n",
      "         0.95608363,  0.6439902 ,  0.42385505,  0.60639321],\n",
      "       [ 0.0191932 ,  0.30157482,  0.66017354,  0.29007761,  0.61801543,\n",
      "         0.4287687 ,  0.13547406,  0.29828233,  0.56996491],\n",
      "       [ 0.59087276,  0.57432525,  0.65320082,  0.65210327,  0.43141844,\n",
      "         0.8965466 ,  0.36756187,  0.43586493,  0.89192336],\n",
      "       [ 0.80619399,  0.70388858,  0.10022689,  0.91948261,  0.7142413 ,\n",
      "         0.99884701,  0.1494483 ,  0.86812606,  0.16249293],\n",
      "       [ 0.61555956,  0.12381998,  0.84800823,  0.80731896,  0.56910074,\n",
      "         0.4071833 ,  0.069167  ,  0.69742877,  0.45354268]]), 1: array([[ 0.7220556 ,  0.86638233,  0.97552151,  0.85580334,  0.01171408],\n",
      "       [ 0.35997806,  0.72999056,  0.17162968,  0.52103661,  0.05433799],\n",
      "       [ 0.19999652,  0.01852179,  0.7936977 ,  0.22392469,  0.34535168],\n",
      "       [ 0.92808129,  0.7044144 ,  0.03183893,  0.16469416,  0.6214784 ],\n",
      "       [ 0.57722859,  0.23789282,  0.934214  ,  0.61396596,  0.5356328 ],\n",
      "       [ 0.58990998,  0.73012203,  0.311945  ,  0.39822106,  0.20984375],\n",
      "       [ 0.18619301,  0.94437239,  0.7395508 ,  0.49045881,  0.22741463],\n",
      "       [ 0.25435648,  0.05802916,  0.43441663,  0.31179588,  0.69634349],\n",
      "       [ 0.37775184,  0.17960368,  0.02467873,  0.06724963,  0.67939277]]), 2: array([[ 0.45369684],\n",
      "       [ 0.53657921],\n",
      "       [ 0.89667129],\n",
      "       [ 0.99033895],\n",
      "       [ 0.21689698]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 14085/25000 [02:53<02:11, 82.89it/s]"
     ]
    }
   ],
   "source": [
    "neuralNetwork.train(25000,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118 545 151]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.choice(len(test_features), size=3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69      ,  0.93      , -0.65151592,  0.63972128, -0.34122379,\n",
       "         0.        ,  0.        ,  0.63607114,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.29      ,  0.77      , -0.65151592, -0.9821244 , -0.34122379,\n",
       "         1.        ,  0.        , -0.93333683,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ],\n",
       "       [ 0.64      ,  0.9       ,  1.78237878, -1.16232948,  1.02851142,\n",
       "         0.        ,  0.        ,  2.20547911,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.values[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.0\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "for i in range(len(test_features.values)):\n",
    "    r = neuralNetwork.feed_forward(test_features.values[i])\n",
    "    temp = 0\n",
    "    if r > 0.50:\n",
    "        temp = 1 \n",
    "    else :\n",
    "        temp = 0   \n",
    "    if(test_target.values[i][0] == temp):\n",
    "        correct = correct+1    \n",
    "        \n",
    "print(correct/len(test_data)*100)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
